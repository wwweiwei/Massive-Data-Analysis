{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Massive Data Analysis \n",
    "### HW4 - Finding Similar Articles\n",
    "106070038 杜葳葳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "匯入 SparkConf、SparkContext、Pyspark模組<br>\n",
    "設定環境變數（解決版本問題）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "from pyspark import SparkConf,SparkContext\n",
    "import pyspark\n",
    "from numpy import array\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# set environment variables\n",
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立 SparkConf 物件<br>\n",
    "設為 local 模式、名稱設為 \"hw4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://sd204175.ya.ab.nthu.edu.tw:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>hw4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=hw4>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"hw4\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀檔＆前處理\n",
    "去掉”-“、”.“、”\\n“、\",\"、”'“、”\\“<br>\n",
    "全部改成小寫<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.txt', '002.txt', '003.txt', '004.txt', '005.txt', '006.txt', '007.txt', '008.txt', '009.txt', '010.txt', '011.txt', '012.txt', '013.txt', '014.txt', '015.txt', '016.txt', '017.txt', '018.txt', '019.txt', '020.txt', '021.txt', '022.txt', '023.txt', '024.txt', '025.txt', '026.txt', '027.txt', '028.txt', '029.txt', '030.txt', '031.txt', '032.txt', '033.txt', '034.txt', '035.txt', '036.txt', '037.txt', '038.txt', '039.txt', '040.txt', '041.txt', '042.txt', '043.txt', '044.txt', '045.txt', '046.txt', '047.txt', '048.txt', '049.txt', '050.txt', '051.txt', '052.txt', '053.txt', '054.txt', '055.txt', '056.txt', '057.txt', '058.txt', '059.txt', '060.txt', '061.txt', '062.txt', '063.txt', '064.txt', '065.txt', '066.txt', '067.txt', '068.txt', '069.txt', '070.txt', '071.txt', '072.txt', '073.txt', '074.txt', '075.txt', '076.txt', '077.txt', '078.txt', '079.txt', '080.txt', '081.txt', '082.txt', '083.txt', '084.txt', '085.txt', '086.txt', '087.txt', '088.txt', '089.txt', '090.txt', '091.txt', '092.txt', '093.txt', '094.txt', '095.txt', '096.txt', '097.txt', '098.txt', '099.txt', '100.txt', '101.txt']\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "## 資料夾目錄 \n",
    "path = \"./Downloads/athletics\"\n",
    "## 得到資料夾下的所有檔名稱\n",
    "files= os.listdir(path) \n",
    "## 排序\n",
    "files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "print(files)\n",
    "dataset = [] \n",
    "count = 0\n",
    "for file in files:\n",
    "    count = count + 1\n",
    "    f = open(path+\"/\"+file)\n",
    "    data = f.read()\n",
    "    data = data.replace(\"-\",\" \").replace(\".\",\"\").replace(\"\\n\",\" \").replace(\",\",\"\").replace(\"'\",\"\").replace(\"\\\"\",\"\")\n",
    "    data = data.lower()\n",
    "    data = data.split(\" \")\n",
    "    while \"\" in data:\n",
    "        data.remove(\"\")\n",
    "    dataset.append(data)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立RDD,將每個doc加上index\n",
    "data = sc.parallelize(dataset).zipWithIndex().map(lambda x: (x[1]+1,x[0]))\n",
    "#data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 資料型別\n",
    "* List 用中括號 [] 表示:<br>\n",
    "    有順序，可改變內容的序列\n",
    "* Tuple 用小括號 () 表示:<br>\n",
    "    有順序，不可改變內容的序列\n",
    "* Set 用大括號 {} 表示:<br>\n",
    "    資料的集合，沒有順序，沒有重複，且為可改變內容\n",
    "* Dict 用大括號 {} 表示:<br>\n",
    "    沒有順序，沒有重複，且為可改變內容的多個鍵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Shingling\n",
    "Convert Doc to Sets<br>\n",
    "k=3,將每三個words放入一個tuple<br>\n",
    "並將每個doc中的所有tuple放入同個set中<br>\n",
    "因為set內的元素不可重複,重複的只會被算到一次,剛好符合shingling中的要求<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_shingle(data):\n",
    "    text = data[1]\n",
    "    total_shingle = len(data[1])-3 +1\n",
    "    shingle_list = []\n",
    "    for i in range(total_shingle):\n",
    "        shingle_list.append([text[i],text[i+1],text[i+2]])   \n",
    "        \n",
    "    shingle_set = set(tuple(s) for s in shingle_list)\n",
    "    return(data[0],shingle_set)\n",
    "tuple_data = data.map(three_shingle)\n",
    "#tuple_data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing Shingles\n",
    "將shingles做hashing處理<br>\n",
    "因為實際內容不重要,只在意相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapAndHash (data):\n",
    "    maplist = []\n",
    "    for i in data[1]:\n",
    "        maplist.append((data[0],hash(i)))\n",
    "    return maplist\n",
    "shingle_data = tuple_data.flatMap(mapAndHash)\n",
    "#shingle_data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Minhashing\n",
    "Permuting 的計算量太大<br>\n",
    "所以使用100個隨機哈希函數來模擬隨機排列轉換的效果<br>\n",
    "根據哈希之後的位置建構Signature Matrix<br>\n",
    "一開始將所有Signature Matrix的值都設為無限大<br>\n",
    "接著尋找第r行為1,更新Signature Matrix為最小值<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universal Hashing** <br>\n",
    "ha,b(x)=((ax+b)mod P)mod N<br>\n",
    "a,b: random integers<br>\n",
    "N: 相異shingle個數<br>\n",
    "P: prime number(P>N)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "    for i in range(2, n):\n",
    "        if n % i == 0: \n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_prime(n):\n",
    "    while is_prime(n) == False:\n",
    "        n = n+1\n",
    "    else:\n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingle_count = shingle_data.map(lambda x : (x[1],1)).reduceByKey(lambda x,y : x+y)\n",
    "N = shingle_count.count()\n",
    "P = find_prime(N)\n",
    "\n",
    "np.random.seed(1)\n",
    "a = np.random.randint(0, 100000, size = 100)\n",
    "b = np.random.randint(0, 100000, size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 26571<br>\n",
    "P = 26573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用100個hash function產生出長度為100的array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_value = shingle_data.map(lambda x : (x[0], (x[1]*a+b)%P%N))\n",
    "#hash_value.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到100個hash function分別算出來的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_value(a,b):\n",
    "    for i in range(100):\n",
    "        if a[i] < b[i]: \n",
    "            a[i] = a[i]  \n",
    "        else:\n",
    "            a[i] = b[i]\n",
    "    return a\n",
    "min_hash = hash_value.reduceByKey(lambda x,y : min_value(x,y))\n",
    "#min_hash.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Locality-sensitive hashing \n",
    "b = 50, r = 2 <br>\n",
    "劃分成50個band、2個行<br>\n",
    "對每個band,存在一個hash能將band的每r個整數組成的列向量映射到數個大數目範圍的桶中,<br>\n",
    "因為相似項比不相似項有更大機率哈希到同一個bucket,<br>\n",
    "將至少有一次hash到同一個bucket的文檔看成candidate pair,<br>\n",
    "檢查所有candidate pair的相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把原本長度為100的min_hash map到 50個不同的band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_bucket(min_hash):\n",
    "    List=[]\n",
    "    for i in range(50):\n",
    "        hash_value = hash((min_hash[1][2*i],min_hash[1][2*i+1]))\n",
    "        List.append((min_hash[0],(i+1,hash_value)))\n",
    "    return List\n",
    "hash_buckets = min_hash.flatMap(hash_bucket).map(lambda x: (x[1],[x[0]])) \n",
    "#hash_buckets.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到 candidate pair\n",
    "將一個以上的band hash到同個bucket做為candidate pair<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pair = hash_buckets.reduceByKey(lambda x,y : x+y).values()\n",
    "candidate_pair = candidate_pair.filter(lambda x: len(x)>=1)\n",
    "#candidate_pair.take(10)\n",
    "pairs = candidate_pair.flatMap(lambda x: list(itertools.combinations(x,2)))\n",
    "pairs_count = pairs.map(lambda x: (x,1)).reduceByKey(lambda x,y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs_count.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "top 10 indices of candidate pairs and their similarities in decreasingly order. (index1, index2) : similarity <br>\n",
    "先整理一下,再計算相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_1 = list(pairs_count.map(lambda x: x[0][0]).collect())\n",
    "C_2 = list(pairs_count.map(lambda x: x[0][1]).collect())\n",
    "C_12 = list(pairs_count.map(lambda x: x[0]).collect())\n",
    "#C_12\n",
    "columns_1 = min_hash.filter(lambda x : x[0] in C_1)\n",
    "columns_2 = min_hash.filter(lambda x : x[0] in C_2)\n",
    "#columns_1.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_pairs = columns_1.cartesian(columns_2).map(lambda x: ( (x[0][0],x[1][0]), (x[0][1],x[1][1]) )).filter(lambda x: x[0] in pairs_12)\n",
    "#similar_pairs.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算 Jaccard Similarity \n",
    "相同的min-hash數量/全部的hash數量(100)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard_Similarity(data):\n",
    "    count = 0\n",
    "    for i in range(100):\n",
    "        if data[1][0][i]==data[1][1][i]:\n",
    "            count=count+1\n",
    "    return (data[0],count/100)\n",
    "similarity = similar_pairs.map(Jaccard_Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((12, 20), 1.0),\n",
       " ((52, 84), 1.0),\n",
       " ((30, 35), 0.77),\n",
       " ((47, 49), 0.75),\n",
       " ((49, 88), 0.52),\n",
       " ((23, 38), 0.48),\n",
       " ((48, 49), 0.48),\n",
       " ((14, 40), 0.45),\n",
       " ((47, 88), 0.39),\n",
       " ((47, 48), 0.36),\n",
       " ((50, 51), 0.13),\n",
       " ((13, 21), 0.12),\n",
       " ((45, 91), 0.12),\n",
       " ((81, 82), 0.08),\n",
       " ((82, 89), 0.07),\n",
       " ((34, 43), 0.05),\n",
       " ((81, 89), 0.05),\n",
       " ((9, 14), 0.04),\n",
       " ((3, 70), 0.04),\n",
       " ((14, 68), 0.04),\n",
       " ((71, 98), 0.04),\n",
       " ((1, 42), 0.03),\n",
       " ((3, 94), 0.03),\n",
       " ((14, 58), 0.03),\n",
       " ((22, 61), 0.03),\n",
       " ((33, 50), 0.03),\n",
       " ((40, 58), 0.03),\n",
       " ((40, 68), 0.03),\n",
       " ((41, 43), 0.03),\n",
       " ((33, 81), 0.03),\n",
       " ((33, 82), 0.03),\n",
       " ((37, 70), 0.03),\n",
       " ((60, 74), 0.03),\n",
       " ((13, 61), 0.02),\n",
       " ((18, 50), 0.02),\n",
       " ((33, 89), 0.02),\n",
       " ((40, 98), 0.02)]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = similarity.map(lambda x : (x[1],x[0])).sortByKey(False).map(lambda x : (x[1],x[0]))\n",
    "ans.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "調整格式,印出前十高的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 20) : 100.0%\n",
      "(52, 84) : 100.0%\n",
      "(30, 35) : 77.0%\n",
      "(47, 49) : 75.0%\n",
      "(49, 88) : 52.0%\n",
      "(23, 38) : 48.0%\n",
      "(48, 49) : 48.0%\n",
      "(14, 40) : 45.0%\n",
      "(47, 88) : 39.0%\n",
      "(47, 48) : 36.0%\n"
     ]
    }
   ],
   "source": [
    "top_10 = ans.take(10)\n",
    "for i in top_10:\n",
    "    sim = float(i[1])*100\n",
    "    string = \"(\"+str(i[0][0])+\", \"+str(i[0][1]) + \") : \" + str(sim)+ \"%\"\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Output\n",
    "(12, 20) : 100.0% <br>\n",
    "(52, 84) : 100.0% <br>\n",
    "(30, 35) : 77.0% <br>\n",
    "(47, 49) : 75.0% <br>\n",
    "(49, 88) : 52.0% <br>\n",
    "(23, 38) : 48.0% <br>\n",
    "(48, 49) : 48.0% <br>\n",
    "(14, 40) : 45.0% <br>\n",
    "(47, 88) : 39.0% <br>\n",
    "(47, 48) : 36.0%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
